{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ET5003_Etivity2_OlgaMinguett_20179766_merge.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "VYFvbgYDaEOS",
        "h51OhBV5Z4tY",
        "bfSEdYAUoIDn",
        "YGmB9BNkoIDr"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olgaminguett/ET5003_SEM1_2021-2/blob/main/Week-3/ET5003_Etivity2_OlgaMinguett_20179766_merge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "930vlW5BrOtq"
      },
      "source": [
        "<div>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1vK33e_EqaHgBHcbRV_m38hx6IkG0blK_\" width=\"350\"/>\n",
        "</div> \n",
        "\n",
        "#**Artificial Intelligence - MSc**\n",
        "##ET5003 - MACHINE LEARNING APPLICATIONS \n",
        "\n",
        "###Instructor: Enrique Naredo\n",
        "###ET5003_Etivity-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqXD_IwUQuBF",
        "cellView": "form"
      },
      "source": [
        "#@title Current Date\n",
        "Today = '2021-09-20' #@param {type:\"date\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzDKau31OjVO",
        "cellView": "form"
      },
      "source": [
        "#@markdown ---\n",
        "#@markdown ### Enter your details here:\n",
        "Student_ID = \"20179766\" #@param {type:\"string\"}\n",
        "Student_full_name = \"Olga Minguett\" #@param {type:\"string\"}\n",
        "#@markdown ---"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r39xGZckTpKx",
        "cellView": "form"
      },
      "source": [
        "#@title Notebook information\n",
        "Notebook_type = 'Etivity' #@param [\"Example\", \"Lab\", \"Practice\", \"Etivity\", \"Assignment\", \"Exam\"]\n",
        "Version = 'Draft' #@param [\"Draft\", \"Final\"] {type:\"raw\"}\n",
        "Submission = False #@param {type:\"boolean\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A0Z6S-r6DpA"
      },
      "source": [
        "# INTRODUCTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkRchZtf6IV-"
      },
      "source": [
        "**Piecewise regression**, extract from [Wikipedia](https://en.wikipedia.org/wiki/Segmented_regression):\n",
        "\n",
        "Segmented regression, also known as piecewise regression or broken-stick regression, is a method in regression analysis in which the independent variable is partitioned into intervals and a separate line segment is fit to each interval. \n",
        "\n",
        "* Segmented regression analysis can also be performed on \n",
        "multivariate data by partitioning the various independent variables. \n",
        "* Segmented regression is useful when the independent variables, clustered into different groups, exhibit different relationships between the variables in these regions. \n",
        "\n",
        "* The boundaries between the segments are breakpoints.\n",
        "\n",
        "* Segmented linear regression is segmented regression whereby the relations in the intervals are obtained by linear regression. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aajlS0WCJ8pm"
      },
      "source": [
        "***The goal is to use advanced Machine Learning methods to predict House price.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wg7VCbX77eAA"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYPJU_Y6O6Dq"
      },
      "source": [
        "# Suppressing Warnings:\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# to plot\n",
        "import seaborn as sns\n",
        "import matplotlib.colors\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# to generate classification, regression and clustering datasets\n",
        "import sklearn.datasets as dt\n",
        "\n",
        "# to create data frames\n",
        "import pandas as pd\n",
        "\n",
        "# to generate data from an existing dataset\n",
        "from sklearn.neighbors import KernelDensity\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# to use mathematical functions\n",
        "import numpy as np\n",
        "\n",
        "# for Bayesian statistical modeling and probabilistic ML\n",
        "import pymc3 as pm\n",
        "\n",
        "# for exploratory analysis of Bayesian models\n",
        "import arviz as az\n",
        "\n",
        "# Standardize features by removing the mean and scaling to unit variance\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MUJdlxSPSMM"
      },
      "source": [
        "# Define the seed so that results can be reproduced\n",
        "seed = 11\n",
        "rand_state = 11\n",
        "\n",
        "# Define the color maps for plots\n",
        "color_map = plt.cm.get_cmap('RdYlBu')\n",
        "color_map_discrete = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"red\",\"cyan\",\"magenta\",\"blue\"])\n",
        "\n",
        "# set a grey background (use sns.set_theme() if seaborn version 0.11.0 or above) \n",
        "sns.set(style=\"darkgrid\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WL91ShB19RPw"
      },
      "source": [
        "# DATASET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESg5DGKWJSOf"
      },
      "source": [
        "Extract from this [paper](https://ieeexplore.ieee.org/document/9300074):\n",
        "\n",
        "* House prices are a significant impression of the economy, and its value ranges are of great concerns for the clients and property dealers. \n",
        "\n",
        "* Housing price escalate every year that eventually reinforced the need of strategy or technique that could predict house prices in future. \n",
        "\n",
        "* There are certain factors that influence house prices including physical conditions, locations, number of bedrooms and others.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8Y2pf50FlYL"
      },
      "source": [
        "1. [Download the dataset](https://github.com/UL-ET5003/ET5003_SEM1_2021-2/tree/main/Week-3). \n",
        "\n",
        "2. Upload the dataset into your folder.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMkdCQEmKTof"
      },
      "source": [
        "The challenge is to predict the final price of each house."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uXMRJFn8eu1"
      },
      "source": [
        "## Read Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jw3S2Yp8nwd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdi6L4at8zN0"
      },
      "source": [
        "# Path, copy the path from your Drive\n",
        "syntPath = '/content/drive/My Drive/Colab Notebooks/house-data/' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBJZkkFp9Kme"
      },
      "source": [
        "# House Data\n",
        "house_train = syntPath + 'house_train.csv'\n",
        "house_test = syntPath + 'house_test.csv'\n",
        "true_price = syntPath + 'true_price.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDMWeNUfeD78"
      },
      "source": [
        "# Read datasets\n",
        "house_train = pd.read_csv(house_train)\n",
        "house_test = pd.read_csv(house_test)\n",
        "true_price = pd.read_csv(true_price)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9ZjHEKfwk-m"
      },
      "source": [
        "## Data Examination"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrIrNE-c2MYD"
      },
      "source": [
        "###Â True Price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKHgprEbvYAo"
      },
      "source": [
        "true_price.sample(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA2diFb_5J7F"
      },
      "source": [
        "# Rename columns in the existing DataFrame\n",
        "true_price.rename(columns={'Id': 'ad_id'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUo_3X0uvjNS"
      },
      "source": [
        "#Concise summary of the dataframe\n",
        "true_price.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WpWKo6W2kkj"
      },
      "source": [
        "#Returns the dimensions of the array - Rows & Columns\n",
        "true_price.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQs_da6V2QF4"
      },
      "source": [
        "###Â House Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKKXocZxkwAm"
      },
      "source": [
        "# Concat datasets to preprocess \n",
        "frames = [house_train, house_test]\n",
        "house_data = pd.concat(frames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNFLYITCnuVU"
      },
      "source": [
        "# Print 5 sample rows of the dataframe\n",
        "house_data.sample(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm17QKBxkvwq"
      },
      "source": [
        "# Print first 5 rows of the dataframe\n",
        "house_data.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wTj2P0YkvkX"
      },
      "source": [
        "# Print last 5 rows of the dataframe\n",
        "house_data.tail(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-Ucg3kLoHP3"
      },
      "source": [
        "#Returns column name\n",
        "house_data.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OV0r8iVMoRxg"
      },
      "source": [
        "#Returns the dimensions of the array\n",
        "#Rows & Columns\n",
        "house_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goelkt03nlnX"
      },
      "source": [
        "#Concise summary of the dataframe\n",
        "house_data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99rydwospDg1"
      },
      "source": [
        "# Missing Values\n",
        "house_data.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rRLlZx4nlkT"
      },
      "source": [
        "#Percentage of NAN Values\n",
        "house_data.isna().mean().round(4) * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3xQN96VwG-u"
      },
      "source": [
        "## Process and Encode the Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0bUby91o9YE"
      },
      "source": [
        "### Missing Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vrIWy3LokZY"
      },
      "source": [
        "\n",
        "#### Numerical Attributes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bkvxvxdnlfX"
      },
      "source": [
        "#Representation of the distribution of data\n",
        "house_data.hist(figsize=[10,10]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q3e9AFaxXQs"
      },
      "source": [
        "Bathrooms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UotbTPxvxZLj"
      },
      "source": [
        "house_data.dropna(subset=['bathrooms'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFlhU6tqy8FR"
      },
      "source": [
        "Number of Units"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sznoq0way8i3"
      },
      "source": [
        "house_data.drop('no_of_units', axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7APBYBIzx-e5"
      },
      "source": [
        "Price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ohzc6nbyAJG"
      },
      "source": [
        "house_data.dropna(subset=['price'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ5EtWVYsjWi"
      },
      "source": [
        "Surface"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FDcMIUtsjvy"
      },
      "source": [
        "house_data['surface'].fillna(house_data['surface'].median(), inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05SAL8mEpTP3"
      },
      "source": [
        "#### Categorical Attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ACIEkktuOyJ"
      },
      "source": [
        "Area"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uifAgY8hdlmU"
      },
      "source": [
        "house_data['area'].replace({'Temple Bar':'Dublin 1', 'IFSC':'Dublin 1', \n",
        "                            'Grand Canal Dock':'Dublin 2',\n",
        "                            'Clontarf':'Dublin 3', 'East Wall':'Dublin 3', 'North Strand':'Dublin 3', 'Fairview':'Dublin 3', 'Marino':'Dublin 3', 'Ballyboughal':'Dublin 3', \n",
        "                            'Ballsbridge':'Dublin 4', 'Donnybrook':'Dublin 4','Sandymount':'Dublin 4','Ringsend':'Dublin 4','Irishtown':'Dublin 4','Merrion':'Dublin 4',\n",
        "                            'Artane':'Dublin 5','Raheny':'Dublin 5','Kilbarrack':'Dublin 5','Edenmore':'Dublin 5','Kilmore':'Dublin 5','Donnycarney':'Dublin 5',\n",
        "                            'Rathmines':'Dublin 6','Rathgar':'Dublin 6','Ranelagh':'Dublin 6','Milltown':'Dublin 6','Dartry':'Dublin 6',\n",
        "                            'Stoneybatter':'Dublin 7','Phibsborough':'Dublin 7','Navan Road (D7)':'Dublin 7','North Circular Road':'Dublin 7','Smithfield':'Dublin 7','Ashtown':'Dublin 7','Cabra':'Dublin 7',\n",
        "                            'Kilmainham':'Dublin 8','Inchicore':'Dublin 8','Rialto':'Dublin 8','Portobello':'Dublin 8','South Circular Road':'Dublin 8','Islandbridge':'Dublin 8','The Coombe':'Dublin 8',\"Dolphin's Barn\":'Dublin 8','Christchurch':'Dublin 8',\n",
        "                            'Drumcondra':'Dublin 9','Glasnevin':'Dublin 9','Santry':'Dublin 9','Whitehall':'Dublin 9','Beaumont':'Dublin 9','Ballymun':'Dublin 9','Poppintree':'Dublin 9',\n",
        "                            'Ballyfermot':'Dublin 10','Cherry Orchard':'Dublin 10',\n",
        "                            'Finglas':'Dublin 11',\"St Margaret's\":'Dublin 11',\n",
        "                            'Walkinstown':'Dublin 12','Crumlin':'Dublin 12','Drimnagh':'Dublin 12','Bluebell':'Dublin 12','Park West':'Dublin 12','Perrystown':'Dublin 12',\n",
        "                            'Malahide':'Dublin 13','Howth':'Dublin 13','Sutton':'Dublin 13','Baldoyle':'Dublin 13','Donaghmede':'Dublin 13','Bayside':'Dublin 13','Ard Na Greine':'Dublin 13','Clongriffin':'Dublin 13','Clarehall':'Dublin 13',\n",
        "                            'Dundrum':'Dublin 14','Churchtown':'Dublin 14','Goatstown':'Dublin 14','Clonskeagh':'Dublin 14','Windy Arbour':'Dublin 14',\n",
        "                            'Carpenterstown':'Dublin 15','Castleknock':'Dublin 15','Clonsilla':'Dublin 15','Blanchardstown':'Dublin 15','Clonee':'Dublin 15','Coolmine':'Dublin 15','Hartstown':'Dublin 15','Mulhuddart':'Dublin 15','The Ward':'Dublin 15','Ongar':'Dublin 15','Tyrrelstown':'Dublin 15',\n",
        "                            'Rathfarnham':'Dublin 16','Ballinteer':'Dublin 16','Ballinascorney':'Dublin 16','Knocklyon':'Dublin 16',\n",
        "                            'Darndale':'Dublin 17','Clonshaugh':'Dublin 17','Coolock':'Dublin 17','Killester':'Dublin 17',\n",
        "                            'Deansgrange':'Dublin 18','Sandyford':'Dublin 18','Foxrock':'Dublin 18','Stepaside':'Dublin 18','Cabinteely':'Dublin 18','Carrickmines':'Dublin 18','Leopardstown':'Dublin 18','Kilternan':'Dublin 18','Shankill':'Dublin 18',\n",
        "                            'Palmerstown':'Dublin 20','Chapelizod':'Dublin 20','Lucan':'Dublin 20',\n",
        "                            'Clondalkin':'Dublin 22','Kingswood':'Dublin 22','Newcastle':'Dublin 22',\n",
        "                            'Ballymount':'Dublin 24','Kiltipper':'Dublin 24','Tallaght':'Dublin 24','Balrothery':'Dublin 24','Rathcoole':'Dublin 24','Kilnamanagh':'Dublin 24','Firhouse':'Dublin 24','Greenhills':'Dublin 24','Oldbawn':'Dublin 24','Adamstown':'Dublin 24','Saggart':'Dublin 24','Citywest':'Dublin 24','Ballycullen':'Dublin 24','Brittas':'Dublin 24',\n",
        "                            'Terenure':'Dublin 6w',\"Harold's Cross\":'Dublin 6w','Kimmage':'Dublin 6w','Templeogue':'Dublin 6w',\n",
        "                            'Donabate':'Co. Fingal','Swords':'Co. Fingal','Portmarnock':'Co. Fingal','Kinsealy':'Co. Fingal','Balgriffin':'Co. Fingal','Garristown':'Co. Fingal','Naul':'Co. Fingal','Skerries':'Co. Fingal','Rush':'Co. Fingal','Lusk':'Co. Fingal','Balbriggan':'Co. Fingal','Loughshinny':'Co. Fingal','Ballybough':'Co. Fingal',\n",
        "                            'Blackrock':'Co. Dun Laoghaire-Rathdown','Dun Laoghaire':'Co. Dun Laoghaire-Rathdown','Glenageary':'Co. Dun Laoghaire-Rathdown',\n",
        "                            'Monkstown':'Co. Dun Laoghaire-Rathdown','Booterstown':'Co. Dun Laoghaire-Rathdown','Sandycove':'Co. Dun Laoghaire-Rathdown',\n",
        "                            'Rathmichael':'Co. Dun Laoghaire-Rathdown','Mount Merrion':'Co. Dun Laoghaire-Rathdown','Ballybrack':'Co. Dun Laoghaire-Rathdown','Sallynoggin':'Co. Dun Laoghaire-Rathdown',\n",
        "                            'Kilmacud':'Co. Dun Laoghaire-Rathdown','Dalkey':'Co. Dun Laoghaire-Rathdown','Killiney':'Co. Dun Laoghaire-Rathdown','Loughlinstown':'Co. Dun Laoghaire-Rathdown',\n",
        "                            }, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e94xK7rwnlcx"
      },
      "source": [
        "house_data['area'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaomdaV-nxRI"
      },
      "source": [
        "area_mapper = {\n",
        "          'Dublin 1': 1,                      \n",
        "          'Dublin 2': 2,\n",
        "          'Dublin 3': 3,\n",
        "          'Dublin 4': 4,\n",
        "          'Dublin 5': 5,\n",
        "          'Dublin 6': 6,                      \n",
        "          'Dublin 6w': 7,  \n",
        "          'Dublin 7': 8, \n",
        "          'Dublin 8': 9,                    \n",
        "          'Dublin 9': 10,\n",
        "          'Dublin 10': 11,\n",
        "          'Dublin 11': 12,                           \n",
        "          'Dublin 12': 13,                      \n",
        "          'Dublin 13': 14,\n",
        "          'Dublin 14': 15,                   \n",
        "          'Dublin 15': 16,\n",
        "          'Dublin 16': 17, \n",
        "          'Dublin 17': 18,     \n",
        "          'Dublin 18': 19, \n",
        "          'Dublin 20': 20,\n",
        "          'Dublin 22': 21,                    \n",
        "          'Dublin 24': 22,\n",
        "          'Co. Fingal': 23,                    \n",
        "          'Co. Dun Laoghaire-Rathdown': 24\n",
        "          }\n",
        "house_data['area'] = house_data['area'].replace(area_mapper)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMT69QXmuReC"
      },
      "source": [
        "BER Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc2eNUEVnlaZ"
      },
      "source": [
        "house_data['ber_classification'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRcthiaRv6cm"
      },
      "source": [
        "ber_classification_mapper = {\n",
        "    \"A1\": 1,\n",
        "    \"A2\": 2,\n",
        "    \"A3\": 3,\n",
        "    \"B1\": 4,\n",
        "    \"B2\": 5,\n",
        "    \"B3\": 6,\n",
        "    \"C1\": 7,\n",
        "    \"C2\": 8,\n",
        "    \"C3\": 9,\n",
        "    \"D1\": 10,\n",
        "    \"D2\": 11,\n",
        "    \"E1\": 12,\n",
        "    \"E2\": 13,\n",
        "    \"F\": 14,\n",
        "    \"G\": 15,\n",
        "    \"SINo666of2006exempt\": 16,\n",
        "}\n",
        "house_data['ber_classification'] = house_data['ber_classification'].replace(ber_classification_mapper)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjP7askMsPBL"
      },
      "source": [
        "house_data['ber_classification'].fillna(house_data['ber_classification'].median(), inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8VQF__yuVBt"
      },
      "source": [
        "County"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1icn97fnlXe"
      },
      "source": [
        "house_data['county'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C-12NVrml31"
      },
      "source": [
        "house_data.drop('county', axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsY9RMX5uXD7"
      },
      "source": [
        "Description Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY3Dp_DKnlUY"
      },
      "source": [
        "house_data['description_block'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSUitzFUuano"
      },
      "source": [
        "house_data.drop('description_block', axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbwIPgjbutsR"
      },
      "source": [
        "Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjbL53RsnlOZ"
      },
      "source": [
        "house_data['environment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpYQpQ-tmh1O"
      },
      "source": [
        "house_data.drop('environment', axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcyD8oCtuyru"
      },
      "source": [
        "Facility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoUdxkCqnlAh"
      },
      "source": [
        "house_data['facility'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fofDb9G7u-ld"
      },
      "source": [
        "house_data.drop('facility', axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XW7ZNwhWu0zY"
      },
      "source": [
        "Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjNmE6OyqJba"
      },
      "source": [
        "house_data['features'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2EQX_mcvGhT"
      },
      "source": [
        "house_data.drop('features', axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unxbc8Ydu2zk"
      },
      "source": [
        "Property Category"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0cd3hRnqJXA"
      },
      "source": [
        "house_data['property_category'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRF0bMezwyFM"
      },
      "source": [
        "property_category_mapper = {\n",
        "    \"sale\": 0,\n",
        "    \"new_development_parent\": 1\n",
        "}\n",
        "\n",
        "house_data['property_category'] = house_data['property_category'].replace(property_category_mapper)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHeh87u7u4xU"
      },
      "source": [
        "Property Type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXVY6iZcqJTK"
      },
      "source": [
        "house_data['property_type'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsRlqO37waIR"
      },
      "source": [
        "property_type_mapper = {\n",
        "    \"apartment\": 1,\n",
        "    \"bungalow\": 2,\n",
        "    \"detached\": 3,\n",
        "    \"duplex\": 4,\n",
        "    \"end-of-terrace\": 5,\n",
        "    \"semi-detached\": 6,\n",
        "    \"site\": 7,\n",
        "    \"studio\": 8,\n",
        "    \"terraced\": 9,\n",
        "    \"townhouse\": 10\n",
        "}\n",
        "house_data['property_type'] = house_data['property_type'].replace(property_type_mapper)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caceGqg1oyi8"
      },
      "source": [
        "### Outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba-oKMWQXcNH"
      },
      "source": [
        "# Representation of the summary of the set of data values \n",
        "features = ['latitude', 'longitude', 'price', 'bathrooms', 'beds', 'surface']\n",
        "fig = plt.figure(figsize=(20,(len(features))*5))\n",
        "for i in features: \n",
        "  # creating a figure composed of two matplotlib.Axes objects (ax_box and ax_hist)\n",
        "  f, (ax_box, ax_hist) = plt.subplots(2,1, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\n",
        "  \n",
        "  # assigning a graph to each ax\n",
        "  sns.boxplot(house_data[i], ax=ax_box)\n",
        "  sns.histplot(data=house_data, x=i, ax=ax_hist)\n",
        "  \n",
        "  # Remove x axis name for the boxplot\n",
        "  ax_box.set(xlabel='')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FND0jF_1aY5p"
      },
      "source": [
        "house_data[['latitude', 'longitude', 'bathrooms', 'beds', 'surface']].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wR4bOnTIZrZa"
      },
      "source": [
        "house_data['bathrooms'].values[house_data['bathrooms'].values > 7 ] = 7\n",
        "house_data['beds'].values[house_data['beds'].values > 10 ] = 10\n",
        "house_data['surface'].values[house_data['surface'].values > 10000] = 10000\n",
        "house_data['latitude'] = (house_data['latitude'] -51.45843)/2.173 # From Nigel Portley\n",
        "house_data['longitude'] = (house_data['longitude'] +6.521187) # From Nigel Portley"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wk7Bvmj0dLRF"
      },
      "source": [
        "house_data[['latitude', 'longitude', 'bathrooms', 'beds', 'surface']].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNxag3QmtPpj"
      },
      "source": [
        "# Missing Values\n",
        "house_data.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pNprOz2CQsb"
      },
      "source": [
        "#Correlation Matrix\n",
        "plt.figure(figsize=(10, 12))\n",
        "sns.heatmap(house_data.corr(), annot=True);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAGSR0OIonmj"
      },
      "source": [
        "house_data.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PyyF0zy2VkN"
      },
      "source": [
        "**Notes**: \n",
        "- We have two different datasets, `true_price` that represents the real cost of the properties and `house_data` that describes the different properties. Decision was to merge training and test data from this category to run the preprocessing procedures over the full dataset, to afterwards, split it again as needed.\n",
        "- True Price has 500 records and 2 columns, with no missing values, `Id` columns has being renamed as it works as the identifier to determine the expected prices from the properties in the house data.\n",
        "- House data has 3482 and 17 columns, with some missing values. We are going to do some data processing to both types of columns, numerical and categorical, and assess their importance to the problem.\n",
        "- According to the House data info, we have 9 categorical variables and 8 numerical variables.\n",
        "\n",
        "**Numerical Variables**:\n",
        "- `no_of_units` dropped as it has over 98% of missing values\n",
        "- `bathrooms`, `beds` and `property_type` contains the same amount of missing values, we inferred that dropping the missing values will affect the others, and it was the case. `bathrooms` and `beds` outliers were removed reassigning those values to the a max of 7 and 10 respectively.\n",
        "- `price` considering that the main goal is to predict the property prices, with missing values that reach 16.94%. Prefered to drop them, instead of infered them, depending on accuracy, this step could change. \n",
        "- `surface` all mising values which represented 15.82%, were fill up with the median. The outliers were removed reassigning those values to the a max of 10.000 sq meters.\n",
        "- `latitude` and `longitude` had no missing values. The outliers were removed reassigning those values were normzalized following Nigel Portley procedure of dividing `latitude` min between 2.173 and `longitude` adding +6.521187\n",
        "\n",
        "**Categorical Variables**:\n",
        "- `area` were converted to numerical variables, replacing the 157 characters, from various cities and towns in County Dublin, County Fingal and County Dun Laoghaire-Rathdown to the various Dublin and Counties that they are located, followed by to a reconfiguration to the correspondent numerical value.\n",
        "- `ber_classification` were converted to numerical variables, replacing the 16 characters. \n",
        "- `county` and `environment` were dropped as they seem to be default values, Dublin and Prod won't yield that much information.\n",
        "- `description_block` is descriptive text, not able to be used. Dropped as consequence.\n",
        "- `facility` is descriptive text, not able to be used. Dropped as consequence.\n",
        "- `features` is descriptive text, not able to be used. Dropped as consequence.\n",
        "- `property_category` were converted to numerical variables, replacing the 2 characters. \n",
        "- `property_type` were converted to numerical variables, replacing the 10 characters. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PMoPLlUJ1Ly"
      },
      "source": [
        "## Training & Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Tvo0nZEZQTy"
      },
      "source": [
        "house_test = house_train[['ad_id']]\n",
        "house_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSlXq_O4eLZt"
      },
      "source": [
        "house_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShrlmLsjfhG_"
      },
      "source": [
        "m = house_test.ad_id.isin(house_data.ad_id)\n",
        "m.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRgMrwEUgBnl"
      },
      "source": [
        "df3 = house_data.merge(house_train, on='ad_id', how='inner')\n",
        "df3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPN9og97hzSa"
      },
      "source": [
        "house_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9r1SnkNc7rM"
      },
      "source": [
        "testing_data = house_test.merge(house_data, how='inner', on=['ad_id'])\n",
        "testing_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gwJIdoceFwp"
      },
      "source": [
        "testing_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loLTHklwKGnV"
      },
      "source": [
        "# split data into training and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "training_data, testing_data = train_test_split(house_data, test_size=500, random_state=25)\n",
        "\n",
        "# training: 70% (0.7), test: 30% (0.3) \n",
        "# you could try any other combination \n",
        "# but consider 50% of training as the low boundary\n",
        "# y = training_data['price']\n",
        "# X = training_data.drop('price', axis=1).values\n",
        "# X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztBkSZluye87"
      },
      "source": [
        "### Train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XUFUPABMHfF"
      },
      "source": [
        "# show first data frame rows \n",
        "training_data.sample()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRH5PE2yyhYB"
      },
      "source": [
        "#Returns the dimensions of the array\n",
        "training_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rq_p-D4yLBe"
      },
      "source": [
        "# Generate descriptive statistics\n",
        "training_data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iqg9_uxFyZli"
      },
      "source": [
        "### Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bw2_yypxMfsi"
      },
      "source": [
        "# show sample data frame rows \n",
        "testing_data.sample()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NflxtG0Tytt4"
      },
      "source": [
        "#Returns the dimensions of the array\n",
        "testing_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXo0x2u7T7-1"
      },
      "source": [
        "# Generate descriptive statistics\n",
        "testing_data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjMH1CSEUA1A"
      },
      "source": [
        "### Expected Cost dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6rA5Ig8y-lN"
      },
      "source": [
        "# show sample data frame rows \n",
        "true_price.sample()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_39AnWhJy-Zy"
      },
      "source": [
        "#Returns the dimensions of the array\n",
        "true_price.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p63sCZeUNx3"
      },
      "source": [
        "# Generate descriptive statistics\n",
        "true_price.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJFJQxAS9HZK"
      },
      "source": [
        "# PIECEWISE REGRESSION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ_1QsLToIDi"
      },
      "source": [
        "## Full Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv5j1KzzMUnm"
      },
      "source": [
        "# select some features columns just for the baseline model\n",
        "# assume not all of the features are informative or useful\n",
        "# in this exercise you could try all of them if possible\n",
        "\n",
        "# Correlation of expected price in df_subset_test \n",
        "df_cost = true_price[true_price.index.isin(df_subset_test.index)]\n",
        "\n",
        "featrain = ['latitude','longitude','beds', 'bathrooms', 'property_type', 'price']\n",
        "# dropna: remove missing values\n",
        "df_subset_train = training_data[featrain].dropna(axis=0)\n",
        "\n",
        "featest = ['latitude','longitude','beds', 'bathrooms', 'property_type']\n",
        "# dropna: remove missing values\n",
        "df_subset_test  =  testing_data[featest].dropna(axis=0)\n",
        "\n",
        "# Correlation of expected price in df_subset_test \n",
        "df_cost = true_price[true_price.index.isin(df_subset_test.index)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEwz_bs3RLOX"
      },
      "source": [
        "len(df_cost)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JIgot9dpKfm"
      },
      "source": [
        "print('Number of nan in df_subset_train dataset: ',df_subset_train.isnull().sum().sum())\n",
        "print('Number of nan in df_subset_test dataset: ',df_subset_test.isnull().sum().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IBRBJhepPVR"
      },
      "source": [
        "# train set, input columns\n",
        "Xs_train = df_subset_train.iloc[:,0:-1].values \n",
        "# train set, output column, cost\n",
        "ys_train = df_subset_train.iloc[:,-1].values.reshape(-1,1)   \n",
        "\n",
        "# test set, input columns\n",
        "Xs_test = df_subset_test.iloc[:,0:].values \n",
        "# test set, output column, cost\n",
        "y_test = df_cost.Expected.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XHaJSURpwjf"
      },
      "source": [
        "# StandardScaler() will normalize the features i.e. each column of X, \n",
        "# so, each column/feature/variable will have Î¼ = 0 and Ï = 1\n",
        "sc = StandardScaler()\n",
        "\n",
        "Xss_train = np.hstack([Xs_train,Xs_train[:,[2]]**2])\n",
        "xscaler = sc.fit(Xss_train)\n",
        "Xn_train = xscaler.transform(Xss_train)\n",
        "\n",
        "Xss_test = np.hstack([Xs_test,Xs_test[:,[2]]**2])\n",
        "Xn_test = xscaler.transform(Xss_test)\n",
        "\n",
        "ylog = np.log(ys_train.astype('float'))\n",
        "yscaler = StandardScaler().fit(ylog)\n",
        "yn_train = yscaler.transform(ylog)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZK2kfygoIDi"
      },
      "source": [
        "# model\n",
        "with pm.Model() as model:\n",
        "    #prior over the parameters of linear regression\n",
        "    alpha = pm.Normal('alpha', mu=0, sigma=30)\n",
        "    #we have one beta for each column of Xn\n",
        "    beta = pm.Normal('beta', mu=0, sigma=30, shape=Xn_train.shape[1])\n",
        "    #prior over the variance of the noise\n",
        "    sigma = pm.HalfCauchy('sigma_n', 5)\n",
        "    #linear regression model in matrix form\n",
        "    mu = alpha + pm.math.dot(beta, Xn_train.T)\n",
        "    #likelihood, be sure that observed is a 1d vector\n",
        "    like = pm.Normal('like', mu=mu, sigma=sigma, observed=yn_train[:,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qca_0nd2yXxt"
      },
      "source": [
        "#number of iterations of the algorithms\n",
        "iter = 50000 \n",
        "\n",
        "# run the model\n",
        "with model:\n",
        "    approximation = pm.fit(iter,method='advi')\n",
        "    \n",
        "# check the convergence\n",
        "plt.plot(approximation.hist);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LlzCFCyybVK"
      },
      "source": [
        "# samples from the posterior\n",
        "posterior = approximation.sample(5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIskuS3ToIDk"
      },
      "source": [
        "# prediction\n",
        "ll=np.mean(posterior['alpha']) + np.dot(np.mean(posterior['beta'],axis=0), Xn_test.T)\n",
        "y_pred_BLR = np.exp(yscaler.inverse_transform(ll.reshape(-1,1)))[:,0]\n",
        "print(\"MAE = \",(np.mean(abs(y_pred_BLR - y_test))))\n",
        "print(\"MAPE = \",(np.mean(abs(y_pred_BLR - y_test) / y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3XUSgWqRBrx"
      },
      "source": [
        "len(y_pred_BLR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTaNBCbnRB38"
      },
      "source": [
        "len(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_jBBKvtoIDk"
      },
      "source": [
        "## Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYFvbgYDaEOS"
      },
      "source": [
        "### Full Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iphQ53UE0iVw"
      },
      "source": [
        "# training gaussian mixture model \n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "gmm = GaussianMixture(n_components=4)\n",
        "# clustering by features 2 to 4\n",
        "ind=[2,3,4]\n",
        "X_ind = np.vstack([Xn_train[:,ind],Xn_test[:,ind]])\n",
        "# Gaussian Mixture\n",
        "gmm.fit(X_ind)\n",
        "# plot blue dots\n",
        "plt.scatter(X_ind[:,0],X_ind[:,1])\n",
        "# centroids:  orange dots\n",
        "plt.scatter(gmm.means_[:,0],gmm.means_[:,1])\n",
        "# lenght of feature clustering\n",
        "len(X_ind)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h51OhBV5Z4tY"
      },
      "source": [
        "### Clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNvx_KxrLt90"
      },
      "source": [
        "# train clusters\n",
        "clusters_train = gmm.predict(Xn_train[:,ind])\n",
        "unique_train, counts_train = np.unique(clusters_train, return_counts=True)\n",
        "dict(zip(unique_train, counts_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wTT4220zFNx"
      },
      "source": [
        "# test clusters\n",
        "clusters_test = gmm.predict(Xn_test[:,ind])\n",
        "unique_test, counts_test = np.unique(clusters_test, return_counts=True)\n",
        "dict(zip(unique_test, counts_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufq873Xmz0l0"
      },
      "source": [
        "# cluster 0\n",
        "Xn0 = Xn_train[clusters_train==0,:]\n",
        "Xtestn0 = Xn_test[clusters_test==0,:]\n",
        "\n",
        "ylog0 = np.log(ys_train.astype('float')[clusters_train==0,:])\n",
        "yscaler0 = StandardScaler().fit(ylog0)\n",
        "yn0 = yscaler0.transform(ylog0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mtUzK6cz0bU"
      },
      "source": [
        "# cluster 1\n",
        "Xn1 = Xn_train[clusters_train==1,:]\n",
        "Xtestn1 = Xn_test[clusters_test==1,:]\n",
        "ylog1 = np.log(ys_train.astype('float')[clusters_train==1,:])\n",
        "yscaler1 = StandardScaler().fit(ylog1)\n",
        "yn1 = yscaler1.transform(ylog1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrWxgCyUz0TV"
      },
      "source": [
        "# cluster 2\n",
        "Xn2 = Xn_train[clusters_train==2,:]\n",
        "Xtestn2 = Xn_test[clusters_test==2,:]\n",
        "ylog2 = np.log(ys_train.astype('float')[clusters_train==2,:])\n",
        "yscaler2 = StandardScaler().fit(ylog2)\n",
        "yn2 = yscaler2.transform(ylog2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmROyZCLz0Kw"
      },
      "source": [
        "# cluster 3\n",
        "Xn3 = Xn_train[clusters_train==3,:]\n",
        "Xtestn3 = Xn_test[clusters_test==3,:]\n",
        "ylog3 = np.log(ys_train.astype('float')[clusters_train==3,:])\n",
        "yscaler3 = StandardScaler().fit(ylog3)\n",
        "yn3 = yscaler3.transform(ylog3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXF25ZDYoIDl"
      },
      "source": [
        "## Piecewise Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1e-4ruvaJci"
      },
      "source": [
        "# model_0\n",
        "with pm.Model() as model_0:\n",
        "  # prior over the parameters of linear regression\n",
        "  alpha = pm.Normal('alpha', mu=0, sigma=30)\n",
        "  # we have a beta for each column of Xn0\n",
        "  beta = pm.Normal('beta', mu=0, sigma=30, shape=Xn0.shape[1])\n",
        "  # prior over the variance of the noise\n",
        "  sigma = pm.HalfCauchy('sigma_n', 5)\n",
        "  # linear regression relationship\n",
        "  #linear regression model in matrix form\n",
        "  mu = alpha + pm.math.dot(beta, Xn0.T)\n",
        "  # likelihood, be sure that observed is a 1d vector\n",
        "  like = pm.Normal('like', mu=mu, sigma=sigma, observed=yn0[:,0])\n",
        "\n",
        "with model_0:\n",
        "  # iterations of the algorithm\n",
        "  approximation = pm.fit(40000,method='advi')\n",
        "\n",
        "# samples from the posterior   \n",
        "posterior0 = approximation.sample(5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5B8vKHZR0XCs"
      },
      "source": [
        "# model_1\n",
        "with pm.Model() as model_1:\n",
        "  # prior over the parameters of linear regression\n",
        "  alpha = pm.Normal('alpha', mu=0, sigma=30)\n",
        "  # we have a beta for each column of Xn\n",
        "  beta = pm.Normal('beta', mu=0, sigma=30, shape=Xn1.shape[1])\n",
        "  # prior over the variance of the noise\n",
        "  sigma = pm.HalfCauchy('sigma_n', 5)\n",
        "  # linear regression relationship\n",
        "  #linear regression model in matrix form\n",
        "  mu = alpha + pm.math.dot(beta, Xn1.T)\n",
        "  # likelihood, # \n",
        "  like = pm.Normal('like', mu=mu, sigma=sigma, observed=yn1[:,0])\n",
        "  \n",
        "with model_1:\n",
        "  # iterations of the algorithm\n",
        "  approximation = pm.fit(40000,method='advi')\n",
        "\n",
        "# samples from the posterior    \n",
        "posterior1 = approximation.sample(5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEACnicT0RvS"
      },
      "source": [
        " # model_2\n",
        "with pm.Model() as model_2:\n",
        "  # prior over the parameters of linear regression\n",
        "  alpha = pm.Normal('alpha', mu=0, sigma=30)\n",
        "  # we have a beta for each column of Xn\n",
        "  beta = pm.Normal('beta', mu=0, sigma=30, shape=Xn2.shape[1])\n",
        "  # prior over the variance of the noise\n",
        "  sigma = pm.HalfCauchy('sigma_n', 5)\n",
        "  # linear regression relationship\n",
        "  # linear regression model in matrix form\n",
        "  mu = alpha + pm.math.dot(beta, Xn2.T)\n",
        "  # likelihood, be sure that observed is a 1d vector\n",
        "  like = pm.Normal('like', mu=mu, sigma=sigma, observed=yn2[:,0])\n",
        "    \n",
        "with model_2:\n",
        "  # iterations of the algorithms\n",
        "  approximation = pm.fit(40000,method='advi')\n",
        "\n",
        "# samples from the posterior    \n",
        "posterior2 = approximation.sample(5000) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1JJI0yH0Rlz"
      },
      "source": [
        "# model_3\n",
        "with pm.Model() as model3:\n",
        "  # prior over the parameters of linear regression\n",
        "  alpha = pm.Normal('alpha', mu=0, sigma=30)\n",
        "  # we have a beta for each column of Xn\n",
        "  beta = pm.Normal('beta', mu=0, sigma=30, shape=Xn3.shape[1])\n",
        "  # prior over the variance of the noise\n",
        "  sigma = pm.HalfCauchy('sigma_n', 5)\n",
        "  # linear regression relationship\n",
        "  mu = alpha + pm.math.dot(beta, Xn3.T)#linear regression model in matrix form\n",
        "  # likelihood, be sure that observed is a 1d vector\n",
        "  like = pm.Normal('like', mu=mu, sigma=sigma, observed=yn3[:,0])\n",
        "    \n",
        "with model3:\n",
        "  # number of iterations of the algorithms\n",
        "  approximation = pm.fit(40000,method='advi')\n",
        "\n",
        "# samples from the posterior     \n",
        "posterior3 = approximation.sample(5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Erb06y6J04LY"
      },
      "source": [
        "# Posterior predictive checks (PPCs)\n",
        "def ppc(alpha,beta,sigma, X,  nsamples=500):\n",
        "    #we select nsamples random samples from the posterior\n",
        "    ind = np.random.randint(0,beta.shape[0],size=nsamples)\n",
        "    alphai = alpha[ind]\n",
        "    betai = beta[ind,:]\n",
        "    sigmai = sigma[ind]\n",
        "\n",
        "    Ypred = np.zeros((nsamples,X.shape[0]))\n",
        "    for i in range(X.shape[0]):\n",
        "        #we generate data from linear model\n",
        "        y_pred = alphai + np.dot(betai, X[i:i+1,:].T).T +np.random.randn(len(sigmai))*sigmai\n",
        "        Ypred[:,i]=y_pred[0,:]\n",
        "    return Ypred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHBgUe1pcZQQ"
      },
      "source": [
        "##Simulations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfSEdYAUoIDn"
      },
      "source": [
        "### Only Cluster 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yzEaEpE08gH"
      },
      "source": [
        "#Simulation\n",
        "Ypred0 = yscaler0.inverse_transform(ppc(posterior0['alpha'],posterior0['beta'],posterior0['sigma_n'],Xn0,  nsamples=200))\n",
        "for i in range(Ypred0.shape[0]):\n",
        "    az.plot_dist( Ypred0[i,:],color='r',plot_kwargs={\"linewidth\": 0.2})\n",
        "az.plot_dist(Ypred0[i,:],color='r',plot_kwargs={\"linewidth\": 0.2}, label=\"prediction\")\n",
        "#plt.plot(np.linspace(-8,8,100),norm.pdf(np.linspace(-8,8,100),df=np.mean(posterior_1['nu'])))\n",
        "#plt.xlim([0,10e7])\n",
        "az.plot_dist(ylog0,label='true observations');\n",
        "plt.legend()\n",
        "plt.xlabel(\"log(y) - output variable\")\n",
        "plt.ylabel(\"density plot\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7b_T2Lh1BhH"
      },
      "source": [
        "### Only Cluster 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZQAf-ZI1GlM"
      },
      "source": [
        "#Simulation\n",
        "Ypred1 = yscaler1.inverse_transform(ppc(posterior1['alpha'],posterior1['beta'],posterior1['sigma_n'],Xn1,  nsamples=200))\n",
        "for i in range(Ypred1.shape[0]):\n",
        "    az.plot_dist( Ypred1[i,:],color='r',plot_kwargs={\"linewidth\": 0.2})\n",
        "az.plot_dist(Ypred1[i,:],color='r',plot_kwargs={\"linewidth\": 0.2}, label=\"prediction\")\n",
        "#plt.plot(np.linspace(-8,8,100),norm.pdf(np.linspace(-8,8,100),df=np.mean(posterior_1['nu'])))\n",
        "#plt.xlim([0,10e7])\n",
        "az.plot_dist(ylog1,label='true observations');\n",
        "plt.legend()\n",
        "plt.xlabel(\"log(y) - output variable\")\n",
        "plt.ylabel(\"density plot\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yW5TaHy1HAF"
      },
      "source": [
        "### Only Cluster 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUdma5t_1IIb"
      },
      "source": [
        "#Simulation\n",
        "Ypred2 = yscaler2.inverse_transform(ppc(posterior2['alpha'],posterior2['beta'],posterior2['sigma_n'],Xn2,  nsamples=200))\n",
        "for i in range(Ypred2.shape[0]):\n",
        "    az.plot_dist( Ypred2[i,:],color='r',plot_kwargs={\"linewidth\": 0.2})\n",
        "az.plot_dist(Ypred2[i,:],color='r',plot_kwargs={\"linewidth\": 0.2}, label=\"prediction\")\n",
        "#plt.plot(np.linspace(-8,8,100),norm.pdf(np.linspace(-8,8,100),df=np.mean(posterior_1['nu'])))\n",
        "#plt.xlim([0,10e7])\n",
        "az.plot_dist(ylog2,label='true observations');\n",
        "plt.legend()\n",
        "plt.xlabel(\"log(y) - output variable\")\n",
        "plt.ylabel(\"density plot\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBxKmM3t1Ig6"
      },
      "source": [
        "### Only Cluster 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSHMYbWV1J_h"
      },
      "source": [
        "#Simulation\n",
        "Ypred3 = yscaler3.inverse_transform(ppc(posterior3['alpha'],posterior3['beta'],posterior3['sigma_n'],Xn3,  nsamples=200))\n",
        "for i in range(Ypred3.shape[0]):\n",
        "    az.plot_dist( Ypred3[i,:],color='r',plot_kwargs={\"linewidth\": 0.2})\n",
        "az.plot_dist(Ypred3[i,:],color='r',plot_kwargs={\"linewidth\": 0.2}, label=\"prediction\")\n",
        "#plt.plot(np.linspace(-8,8,100),norm.pdf(np.linspace(-8,8,100),df=np.mean(posterior_1['nu'])))\n",
        "#plt.xlim([0,10e7])\n",
        "az.plot_dist(ylog3,label='true observations');\n",
        "plt.legend()\n",
        "plt.xlabel(\"log(y) - output variable\")\n",
        "plt.ylabel(\"density plot\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgMUwBO7oIDq"
      },
      "source": [
        "## Overall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adUDX0Ox1VBu"
      },
      "source": [
        "# posteriors\n",
        "Ypred0 = ppc(posterior0['alpha'],posterior0['beta'],posterior0['sigma_n'],Xn0,  nsamples=200)\n",
        "Ypred1 = ppc(posterior1['alpha'],posterior1['beta'],posterior1['sigma_n'],Xn1,  nsamples=200)\n",
        "Ypred2 = ppc(posterior2['alpha'],posterior2['beta'],posterior2['sigma_n'],Xn2,  nsamples=200)\n",
        "Ypred3 = ppc(posterior3['alpha'],posterior3['beta'],posterior3['sigma_n'],Xn3,  nsamples=200)\n",
        "\n",
        "# simulation\n",
        "Ypred = np.hstack([ yscaler0.inverse_transform(Ypred0),\n",
        "                 yscaler1.inverse_transform(Ypred1),\n",
        "                 yscaler2.inverse_transform(Ypred2),\n",
        "                 yscaler3.inverse_transform(Ypred3)])\n",
        "\n",
        "# prediction\n",
        "for i in range(Ypred.shape[0]):\n",
        "    az.plot_dist( Ypred[i,:],color='r',plot_kwargs={\"linewidth\": 0.2})\n",
        "\n",
        "# plot\n",
        "az.plot_dist(Ypred[i,:],color='r',plot_kwargs={\"linewidth\": 0.2}, label=\"prediction\")\n",
        "ylog=np.vstack([ylog0,ylog1,ylog2,ylog3])\n",
        "az.plot_dist(ylog,label='true observations');\n",
        "plt.legend()\n",
        "plt.xlabel(\"log(y) - output variable\")\n",
        "plt.ylabel(\"density plot\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMY9rDvVoIDq"
      },
      "source": [
        "## Test set performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhClcuGl1ZPb"
      },
      "source": [
        "# cluster 0\n",
        "y_pred_BLR0 = np.exp(yscaler0.inverse_transform(np.mean(posterior0['alpha']) \n",
        "              + np.dot(np.mean(posterior0['beta'],axis=0), Xtestn0.T)))\n",
        "print(\"Size Cluster0\", np.sum(clusters_test==0), \", MAE Cluster0=\",\n",
        "      (np.mean(abs(y_pred_BLR0 - y_test[clusters_test==0]))))\n",
        "\n",
        "# cluster 1\n",
        "y_pred_BLR1 = np.exp(yscaler1.inverse_transform(np.mean(posterior1['alpha']) \n",
        "              + np.dot(np.mean(posterior1['beta'],axis=0), Xtestn1.T)))\n",
        "print(\"Size Cluster1\", np.sum(clusters_test==1), \", MAE Cluster1=\",\n",
        "      (np.mean(abs(y_pred_BLR1 - y_test[clusters_test==1]))))\n",
        "\n",
        "# cluster 2\n",
        "y_pred_BLR2 = np.exp(yscaler2.inverse_transform(np.mean(posterior2['alpha']) \n",
        "              + np.dot(np.mean(posterior2['beta'],axis=0), Xtestn2.T)))\n",
        "print(\"Size Cluster2\", np.sum(clusters_test==2), \", MAE Cluster2=\",\n",
        "      (np.mean(abs(y_pred_BLR2 - y_test[clusters_test==2]))))\n",
        "\n",
        "# cluster 3\n",
        "y_pred_BLR3 = np.exp(yscaler3.inverse_transform(np.mean(posterior3['alpha']) \n",
        "              + np.dot(np.mean(posterior3['beta'],axis=0), Xtestn3.T)))\n",
        "print(\"Size Cluster3\", np.sum(clusters_test==3), \", MAE Cluster3=\",\n",
        "      (np.mean(abs(y_pred_BLR3 - y_test[clusters_test==3]))))\n",
        "\n",
        "# joint\n",
        "joint=np.hstack([abs(y_pred_BLR0 - y_test[clusters_test==0]),\n",
        "                 abs(y_pred_BLR1 - y_test[clusters_test==1]),\n",
        "                 abs(y_pred_BLR2 - y_test[clusters_test==2]),\n",
        "                 abs(y_pred_BLR3 - y_test[clusters_test==3])])\n",
        "\n",
        "# MAE\n",
        "print(\"MAE=\",np.mean(joint))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGmB9BNkoIDr"
      },
      "source": [
        "### PPC on the Test set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXom1Pdb1cLW"
      },
      "source": [
        "## Posterior predictive checks (PPCs)\n",
        "num_samples2 = 200\n",
        "Ypred0 = ppc(posterior0['alpha'],posterior0['beta'],posterior0['sigma_n'],Xtestn0, nsamples=num_samples2)\n",
        "Ypred1 = ppc(posterior1['alpha'],posterior1['beta'],posterior1['sigma_n'],Xtestn1, nsamples=num_samples2)\n",
        "Ypred2 = ppc(posterior2['alpha'],posterior2['beta'],posterior2['sigma_n'],Xtestn2, nsamples=num_samples2)\n",
        "Ypred3 = ppc(posterior3['alpha'],posterior3['beta'],posterior3['sigma_n'],Xtestn3, nsamples=num_samples2)\n",
        "\n",
        "# Stack arrays in sequence horizontally (column wise)\n",
        "Ypred = np.hstack([yscaler0.inverse_transform(Ypred0),\n",
        "                 yscaler1.inverse_transform(Ypred1),\n",
        "                 yscaler2.inverse_transform(Ypred2),\n",
        "                 yscaler3.inverse_transform(Ypred3)])\n",
        "\n",
        "# plot prediction shape\n",
        "for i in range(Ypred.shape[0]):\n",
        "    az.plot_dist( Ypred[i,:],color='r',plot_kwargs={\"linewidth\": 0.2})\n",
        "# label\n",
        "az.plot_dist(Ypred[i,:],color='r',plot_kwargs={\"linewidth\": 0.2}, label=\"prediction\")\n",
        "\n",
        "# true observations\n",
        "az.plot_dist(np.log(y_test),label='true observations');\n",
        "plt.legend()\n",
        "plt.xlabel(\"log(y) - output variable\")\n",
        "plt.ylabel(\"density plot\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0GYCpwEM09T"
      },
      "source": [
        "# SUMMARY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2li7DDwd3As"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}